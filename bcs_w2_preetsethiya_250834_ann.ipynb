{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. DATA PREPROCESSING STEP"
      ],
      "metadata": {
        "id": "UKWgHSdfCb38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 1 INSTALLING LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import  LabelEncoder, OneHotEncoder,StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "#step 2 load data\n",
        "data = pd.read_csv('Churn_Modelling.csv')\n",
        "\n",
        "#STEP 3: SEPARATE FEATURES (X) AND TARGET (y)\n",
        "#we exclude rownumber,customerid,surname(indices 0,1,2)\n",
        "#we take data from index 3 upto the last one as features\n",
        "X=data.iloc[:,3:-1].values\n",
        "#we take the last column as target\n",
        "y=data.iloc[:,-1].values\n",
        "\n",
        "# STEP 4: ENCODING CATEGORICAL DATA\n",
        "#label encoding the gender column\n",
        "#gender is at index 2 in our new x matrix (creditscore =0,geography=1,gender =2)\n",
        "le=LabelEncoder()\n",
        "X[:,2]= le.fit_transform(X[:,2])\n",
        "#now female/male are 0/1\n",
        "#one Hot Encoding the \"geography\" column\n",
        "#\"geography\"is at index 1.it has three categories :french,spain ,germany\n",
        "#we transform column1 into 3 separate binary columnc\n",
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n",
        "X=np.array(ct.fit_transform(X))\n",
        "\n",
        "\n",
        "#STEP 5 :SPLITINTO TRAIN AND TEST SET\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "\n",
        "#step 6 :FEATURE SCALLING\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "MFdMXo-SCi8W"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 ARCHITECTURE OF THE BRAIN\n"
      ],
      "metadata": {
        "id": "NmHGMujEMYxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#define the ANN ARCHITECTURE\n",
        "class ChurnPredictor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ChurnPredictor ,self).__init__()\n",
        "\n",
        "    #hidden layer 1\n",
        "    #input :12 features (from our preprocessed data)\n",
        "    #output:8 neurons (arbitrary)\n",
        "    self.layer1=nn.Linear(in_features =12,out_features=8)\n",
        "    #hidden layer 2\n",
        "    #input =8,output=8\n",
        "    self.layer2=nn.Linear(in_features =8,out_features=8)\n",
        "    #output latyer\n",
        "    #input =8,output =1 as only probability is needed\n",
        "    self.output_layer=nn.Linear(in_features=8,out_features=1)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    # 1. pass data through layer 1 and relu function\n",
        "    x=F.relu(self.layer1(x))\n",
        "\n",
        "    #2. Pass data through layer 2 and relu function\n",
        "    x=F.relu(self.layer2(x))\n",
        "\n",
        "    #3. pass through output layer and apply sigmoid  activation\n",
        "    # sigmoid squashes the result between 0 and 1 (Probability)\n",
        "    x=torch.sigmoid(self.output_layer(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "# instantiate the model\n",
        "model = ChurnPredictor()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hqz57y6MiTZ",
        "outputId": "9ee1a625-00e3-4762-91ee-1035de8321fc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChurnPredictor(\n",
            "  (layer1): Linear(in_features=12, out_features=8, bias=True)\n",
            "  (layer2): Linear(in_features=8, out_features=8, bias=True)\n",
            "  (output_layer): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.TRAINING THE  BRAIN"
      ],
      "metadata": {
        "id": "MEz6vBWYUl7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. SETUP THE DATA OR PYTORCH\n",
        "# convert standard numpy arrays into pytorch tensors\n",
        "#.unsqueeze(1) changes y from [0,1,0] to [[0],[1],[0]]\n",
        "X_train_tensor = torch.tensor(X_train,dtype= torch.float32)\n",
        "y_train_tensor= torch.tensor(y_train,dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# 2. DEFINE THE TEACHER AND CORRECTOR\n",
        "criterion=nn.BCELoss() #binary cross entropy loss (teacher)\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.01) #adam optimiser (the corrector)\n",
        "\n",
        "#3. THE TRAINING LOOP\n",
        "epochs=100 # how many times we go through the dataset\n",
        "for epochs in range(epochs):\n",
        "  #A. FORWARD PASS (THE GUESS)\n",
        "  y_pred=model(X_train_tensor)\n",
        "\n",
        "  #B. CALCULATE LOSS(THE GRADE)\n",
        "  loss=criterion(y_pred,y_train_tensor)\n",
        "  #C. BACKWARD PASS(THE Learning )\n",
        "  optimizer.zero_grad() #clear previous calculation\n",
        "  loss.backward() #calculate gradients (how much to adjust each weight)\n",
        "  optimizer.step() #update weights\n",
        "\n",
        "  #monitoring\n",
        "  if(epochs +1)%10 == 0 :\n",
        "    print(f'Epoch [{epochs+1}/{epochs}] ,Loss:{loss.item():.4f}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMNHcoOtUuZ9",
        "outputId": "31191b92-7e72-4b06-e196-4128b34b6776"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/9] ,Loss:0.6534\n",
            "Epoch [20/19] ,Loss:0.4910\n",
            "Epoch [30/29] ,Loss:0.4632\n",
            "Epoch [40/39] ,Loss:0.4384\n",
            "Epoch [50/49] ,Loss:0.4272\n",
            "Epoch [60/59] ,Loss:0.4206\n",
            "Epoch [70/69] ,Loss:0.4137\n",
            "Epoch [80/79] ,Loss:0.4060\n",
            "Epoch [90/89] ,Loss:0.3947\n",
            "Epoch [100/99] ,Loss:0.3789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 .THE EVALUATION PHASE"
      ],
      "metadata": {
        "id": "xkemSAVgaEd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPARE THE TEST DATA\n",
        "X_test_tensor=torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor=torch.tensor(y_test,dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "#2 evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#the exam\n",
        "with torch.no_grad():\n",
        "  #make predictions\n",
        "  y_pred_prob=model(X_test_tensor)\n",
        "\n",
        "  #convert probabilty to yes or no\n",
        "  #if prob >0.5,it rounds to 1 and if prob<0.5 it rounds to 0\n",
        "  y_pred_cls=y_pred_prob.round()\n",
        "\n",
        "  #grade the exam\n",
        "  #.eq() compares predictions vs truth sum() counts the matches\n",
        "  correct_count=y_pred_cls.eq(y_test_tensor).sum().item()\n",
        "  accuracy = correct_count/y_test.shape[0]\n",
        "  print(f\"test accuracy :{accuracy:.4f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgj2r4leaTN_",
        "outputId": "df0601aa-f877-4221-beaa-a63d3ba7c33c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy :0.8225\n"
          ]
        }
      ]
    }
  ]
}